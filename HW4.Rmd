---
title: "Problem Set 4"
author: "Corin Elmore" 
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE,comment=NULL,message=FALSE, include=TRUE, fig.height = 4, fig.width = 8)
```

Push your knitted homework assignment (.Rmd, .md docs, and any other required files or folders) to GitHub by the given deadline. 

### Problem 1: joins
The data set below called `Students` contains information on five students with their ID number, first name and computer preference.

Id | Name | Computer
-- | ---- | -----
1 | Arya | m
2 | Gregor | m
3 | Cersei | w
4 | Jon | m
5 | Jon | w

The data set below called `Classes` contains roster information (student first name and ID).

Class | Student | Stud_Id
------ | -- | --
Econ | Jon | 4
Econ | Arya | 1
Econ | Cersei | 3
Stats | Gregor | 2
Stats | Jon | 4
Stats | Jon | 5
Stats | Arya | 1
CS | Tyrion | 6

What data set will be produced by the following commands? `Describe` the data set in words and `show` what it looks like using an R Markdown table to display the new data set. 

**1.**
```{r, eval=FALSE}
left_join(Classes, Students, by=c("Stud_Id"="Id"))
```

**2.** 
```{r, eval=FALSE}
Econ <- Classes %>% filter(Class == "Econ")
Stats <- Classes %>% filter(Class == "Stats")
inner_join(Stats, Econ, by="Stud_Id")
```

**3.**
```{r, eval=FALSE}
anti_join(Stats, Econ, by="Stud_Id")
```

### Problem 2: restructure
Consider the `Lakes_wide` data set below that records lake clarity (in meters) for 2012 through 2014.

LakeId | 2012 | 2013 | 2014 
---- | ---- | ---- | ----
1 | 6.5 | 5.8 | 5.8 
2 | 2.1 | 3.4 | 2.8

What data set will be produced by the following commands? `Describe` the data set in words and `show` what it looks like using an R Markdown table to display the new data set. 

**1.** 
```{r, eval=FALSE}
gather(Lakes_wide, key = Year, value = Clarity, 2:4)
```

**2.**
```{r, eval=FALSE}
gather(Lakes_wide, key = Year, value = Clarity, 2:4) %>%
  group_by(LakeId) %>%
  arrange(Year) %>%
  mutate(Change_in_Clarity = Clarity - lag(Clarity))
```

### Problem 3: planes
Use the `nycflights13` package and the `flights` and `planes` data frames to answer the questions below. Use the `dplyr` package to answer the questions below. (See `nycflights13` help files for more data set details)

**1.** What variable is the key that connects these two data sets?

**2.** How many planes that flew out of NYC airports in 2013 are in the `planes` data set? How many are **not** in this data set?

**3.** What is the oldest plane (or planes) that flew out of NYC in 2013? Give the tail number(s), the year it was manufactured, and its number of flights from NYC in 2013.

**4.** For the planes flying out of NYC airports in 2013, create a graph that shows the distribution of manufactured year. Describe the distribution. 

### Problem 4
More with the `nycflights13` data. Consider `top_dest`, the top 10 destinations out of NYC area in 2013:
```{r, eval=FALSE}
top_dest <- flights %>% 
  group_by(dest) %>% 
  summarize(N=n()) %>% 
  arrange(desc(N)) %>% 
  slice(1:10)
```

**1.** 
Use a `filtering join` command to create a `flights` data subset that only contains destinations in the `top_dest` top 10 destinations. What is the dimension of this data set? Why does it make sense to use a filtering join here? 

**2.** 
Use your joined data from part `1` to compute the median number of minutes **between flights** (not actual flight duration) to each destination. Which destination has the shortest median time between flights? 

  - **Note:** While the variable `time_hour` records departure time, it is too coarse (rounded to the nearest hour) for our purposes. Use the `make_datetime` function to convert the scheduled departure date/time (year,month,day,hour,minute)  to a date variable.
  - **Hint:** Combine the `interval` and `lag` function to compute the number of minutes between scheduled departures for each destination. 


### Problem 5
MDSR textbook exercise 5.1 (2nd Ed. 6.10).

### Problem 6
MDSR textbook exercise 5.10 (2nd Ed. 5.6).

- **Note:** The `fec` package doesn't appear to exist anymore. I went and downloaded the right datasets for you, but you have to read the documentation file provided below to figure out what the columns mean. The following shows where I have saved each `FEC` file
    - `Contributions by Individuals`:
        - `https://raw.githubusercontent.com/mgelman/data/master/contributions.csv` 
        - [documentation](https://www.fec.gov/campaign-finance-data/contributions-committees-candidates-file-description/)
    - `Candidate Master File`:
        - `https://raw.githubusercontent.com/mgelman/data/master/candidates.csv`
        - [documentation](https://www.fec.gov/campaign-finance-data/candidate-master-file-description/)

- **Hint:** For `Figure 2.2`, the field `TRANSACTION_TP` helps determine whether the funds are supporting or against a candidate.

- **Pro tip:** Include the chunk option `cache=TRUE` in any R chunks that read in large data sets (such as `contributions`). This will cache results of these large R chunks which can reduce the time to `knit` your `.Rmd` after the initial cache. 

